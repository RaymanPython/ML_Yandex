{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание - линейная регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Работа с признаками (8 баллов)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скачайте датасет из материалов к уроку или по ссылке https://raw.githubusercontent.com/jupiterzhuo/travel-insurance/master/travel%20insurance.csv \n",
    "\n",
    "\n",
    "Описание признаков:\n",
    "\n",
    "* Agency — название страхового агентства\n",
    "* Agency Type — тип страхового агентства\n",
    "* Distribution Channel — канал продвижения страхового агентства\n",
    "* Product Name — название страхового продукта\n",
    "* Duration — длительность поездки (количество дней)\n",
    "* Destination — направление поездки\n",
    "* Net Sales — сумма продаж \n",
    "* Commission (in value) — комиссия страхового агентства\n",
    "* Gender — пол застрахованного\n",
    "* Age — возраст застрахованного\n",
    "\n",
    "Ответ:\n",
    "* Claim — потребовалась ли страховая выплата: «да» — 1, «нет» — 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обработайте пропущенные значения и примените написанные функции onehot_encode() и minmax_scale().\n",
    "\n",
    "**Подсказка**: маску для категориальных признаков можно сделать фильтром cat_features_mask = (df.dtypes == \"object\").values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Agency_ADM</th>\n",
       "      <th>Agency_ART</th>\n",
       "      <th>Agency_C2B</th>\n",
       "      <th>Agency_CBH</th>\n",
       "      <th>Agency_CCR</th>\n",
       "      <th>Agency_CSR</th>\n",
       "      <th>Agency_CWT</th>\n",
       "      <th>Agency_EPX</th>\n",
       "      <th>Agency_JWT</th>\n",
       "      <th>Agency_JZI</th>\n",
       "      <th>...</th>\n",
       "      <th>Destination_VIET NAM</th>\n",
       "      <th>Destination_VIRGIN ISLANDS, U.S.</th>\n",
       "      <th>Destination_ZAMBIA</th>\n",
       "      <th>Destination_ZIMBABWE</th>\n",
       "      <th>Net Sales</th>\n",
       "      <th>Commision (in value)</th>\n",
       "      <th>Gender_0</th>\n",
       "      <th>Gender_F</th>\n",
       "      <th>Gender_M</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.300250</td>\n",
       "      <td>0.033757</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.686441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.300250</td>\n",
       "      <td>0.033757</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.601695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.283153</td>\n",
       "      <td>0.104762</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.271186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.291410</td>\n",
       "      <td>0.083810</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.271186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.307923</td>\n",
       "      <td>0.041905</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.347458</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 204 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Agency_ADM  Agency_ART  Agency_C2B  Agency_CBH  Agency_CCR  Agency_CSR  \\\n",
       "0         0.0         0.0         0.0         1.0         0.0         0.0   \n",
       "1         0.0         0.0         0.0         1.0         0.0         0.0   \n",
       "2         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "3         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "4         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "\n",
       "   Agency_CWT  Agency_EPX  Agency_JWT  Agency_JZI  ...  Destination_VIET NAM  \\\n",
       "0         0.0         0.0         0.0         0.0  ...                   0.0   \n",
       "1         0.0         0.0         0.0         0.0  ...                   0.0   \n",
       "2         1.0         0.0         0.0         0.0  ...                   0.0   \n",
       "3         1.0         0.0         0.0         0.0  ...                   0.0   \n",
       "4         1.0         0.0         0.0         0.0  ...                   0.0   \n",
       "\n",
       "   Destination_VIRGIN ISLANDS, U.S.  Destination_ZAMBIA  Destination_ZIMBABWE  \\\n",
       "0                               0.0                 0.0                   0.0   \n",
       "1                               0.0                 0.0                   0.0   \n",
       "2                               0.0                 0.0                   0.0   \n",
       "3                               0.0                 0.0                   0.0   \n",
       "4                               0.0                 0.0                   0.0   \n",
       "\n",
       "   Net Sales  Commision (in value)  Gender_0  Gender_F  Gender_M       Age  \n",
       "0   0.300250              0.033757       0.0       1.0       0.0  0.686441  \n",
       "1   0.300250              0.033757       0.0       1.0       0.0  0.601695  \n",
       "2   0.283153              0.104762       1.0       0.0       0.0  0.271186  \n",
       "3   0.291410              0.083810       1.0       0.0       0.0  0.271186  \n",
       "4   0.307923              0.041905       1.0       0.0       0.0  0.347458  \n",
       "\n",
       "[5 rows x 204 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "def onehot_encode(data, cat_features_mask):\n",
    "    # Создание пустого DataFrame для закодированных признаков\n",
    "    encoded_data = pd.DataFrame()\n",
    "    \n",
    "    # Закодирование категориальных признаков с помощью one-hot encoding\n",
    "    for i, is_cat_feature in enumerate(cat_features_mask):\n",
    "        if is_cat_feature:\n",
    "            encoded_cols = pd.get_dummies(data.iloc[:, i], prefix=data.columns[i])\n",
    "            encoded_data = pd.concat([encoded_data, encoded_cols], axis=1)\n",
    "        else:\n",
    "            encoded_data = pd.concat([encoded_data, data.iloc[:, i]], axis=1)\n",
    "    \n",
    "    return encoded_data\n",
    "\n",
    "\n",
    "def minmax_scale(data, scaler):\n",
    "    # Масштабирование данных с помощью MinMaxScaler\n",
    "    scaled_data = scaler.fit_transform(data)\n",
    "    \n",
    "    # Преобразование масштабированных данных в DataFrame\n",
    "    scaled_data = pd.DataFrame(scaled_data, columns=data.columns)\n",
    "    \n",
    "    return scaled_data\n",
    "\n",
    "\n",
    "# Загрузка данных\n",
    "url = \"https://raw.githubusercontent.com/jupiterzhuo/travel-insurance/master/travel%20insurance.csv\"\n",
    "data = pd.read_csv(url)\n",
    "\n",
    "# Обработка пропущенных значений\n",
    "data.fillna(0, inplace=True)\n",
    "\n",
    "# Создание маски для категориальных признаков\n",
    "cat_features_mask = (data.dtypes == \"object\").values\n",
    "\n",
    "# Применение функции onehot_encode()\n",
    "data_encoded = onehot_encode(data, cat_features_mask)\n",
    "\n",
    "# Применение функции minmax_scale()\n",
    "scaler = MinMaxScaler()\n",
    "data_scaled = minmax_scale(data_encoded, scaler)\n",
    "data_scaled.head()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Agency</th>\n",
       "      <th>Agency Type</th>\n",
       "      <th>Distribution Channel</th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Claim</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Net Sales</th>\n",
       "      <th>Commision (in value)</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CBH</td>\n",
       "      <td>Travel Agency</td>\n",
       "      <td>Offline</td>\n",
       "      <td>Comprehensive Plan</td>\n",
       "      <td>No</td>\n",
       "      <td>186</td>\n",
       "      <td>MALAYSIA</td>\n",
       "      <td>-29.0</td>\n",
       "      <td>9.57</td>\n",
       "      <td>F</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CBH</td>\n",
       "      <td>Travel Agency</td>\n",
       "      <td>Offline</td>\n",
       "      <td>Comprehensive Plan</td>\n",
       "      <td>No</td>\n",
       "      <td>186</td>\n",
       "      <td>MALAYSIA</td>\n",
       "      <td>-29.0</td>\n",
       "      <td>9.57</td>\n",
       "      <td>F</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CWT</td>\n",
       "      <td>Travel Agency</td>\n",
       "      <td>Online</td>\n",
       "      <td>Rental Vehicle Excess Insurance</td>\n",
       "      <td>No</td>\n",
       "      <td>65</td>\n",
       "      <td>AUSTRALIA</td>\n",
       "      <td>-49.5</td>\n",
       "      <td>29.70</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CWT</td>\n",
       "      <td>Travel Agency</td>\n",
       "      <td>Online</td>\n",
       "      <td>Rental Vehicle Excess Insurance</td>\n",
       "      <td>No</td>\n",
       "      <td>60</td>\n",
       "      <td>AUSTRALIA</td>\n",
       "      <td>-39.6</td>\n",
       "      <td>23.76</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CWT</td>\n",
       "      <td>Travel Agency</td>\n",
       "      <td>Online</td>\n",
       "      <td>Rental Vehicle Excess Insurance</td>\n",
       "      <td>No</td>\n",
       "      <td>79</td>\n",
       "      <td>ITALY</td>\n",
       "      <td>-19.8</td>\n",
       "      <td>11.88</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Agency    Agency Type Distribution Channel                     Product Name  \\\n",
       "0    CBH  Travel Agency              Offline               Comprehensive Plan   \n",
       "1    CBH  Travel Agency              Offline               Comprehensive Plan   \n",
       "2    CWT  Travel Agency               Online  Rental Vehicle Excess Insurance   \n",
       "3    CWT  Travel Agency               Online  Rental Vehicle Excess Insurance   \n",
       "4    CWT  Travel Agency               Online  Rental Vehicle Excess Insurance   \n",
       "\n",
       "  Claim  Duration Destination  Net Sales  Commision (in value) Gender  Age  \n",
       "0    No       186    MALAYSIA      -29.0                  9.57      F   81  \n",
       "1    No       186    MALAYSIA      -29.0                  9.57      F   71  \n",
       "2    No        65   AUSTRALIA      -49.5                 29.70      0   32  \n",
       "3    No        60   AUSTRALIA      -39.6                 23.76      0   32  \n",
       "4    No        79       ITALY      -19.8                 11.88      0   41  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подробный анализ и подготовка датасета часто помогают улучшить качество модели. Ниже представлено несколько идей преобразований. Вы можете применить одно или несколько из этих преобразований (а можете не применять), чтобы помочь будущей модели. \n",
    "\n",
    "1. Посмотрите на количественные признаки. Возможно, в некоторых признаках есть выбросы - значения, которые сильно выбиваются. Такие значения полезно удалять. Советуем присмотреться к колонке Duration)\n",
    "\n",
    "2. Можно заметить, что one hot encoding сильно раздувает количество столбцов. Радикальное решение - можно попробовать выбросить все категориальные признаки из датасета.\n",
    "\n",
    "3. Если все-таки оставляете категориальные признаки, то подумайте, как уменьшить количество столбцов после one hot encoding. Признаки с большим количеством значений (Duration - 149! разных стран) можно удалить или попробовать сгруппировать некоторые значения.\n",
    "\n",
    "4. Downsampling. Датасет достаточно большой, разница в классах огромная. Можно уменьшить число наблюдений с частым ответом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'target_column'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3620\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'target_column'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 19>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m sampled_data\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Уменьшение числа наблюдений с частым ответом\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m data_downsampled \u001b[38;5;241m=\u001b[39m \u001b[43mdownsampling\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtarget_column\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36mdownsampling\u001b[1;34m(data, target_column, ratio)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdownsampling\u001b[39m(data, target_column, ratio):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;66;03m# Разделение данных на классы\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m     class_0 \u001b[38;5;241m=\u001b[39m data[\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtarget_column\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      4\u001b[0m     class_1 \u001b[38;5;241m=\u001b[39m data[data[target_column] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# Определение размера выборки для класса 0\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3504\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3505\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3507\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3623\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3624\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3625\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3626\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3627\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3628\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'target_column'"
     ]
    }
   ],
   "source": [
    "def downsampling(data, target_column, ratio):\n",
    "    # Разделение данных на классы\n",
    "    class_0 = data[data[target_column] == 0]\n",
    "    class_1 = data[data[target_column] == 1]\n",
    "    \n",
    "    # Определение размера выборки для класса 0\n",
    "    sample_size = int(len(class_0) * ratio)\n",
    "    \n",
    "    # Случайное выборка из класса 0\n",
    "    sampled_class_0 = class_0.sample(sample_size, random_state=42)\n",
    "    \n",
    "    # Объединение выборки класса 0 и класса 1\n",
    "    sampled_data = pd.concat([sampled_class_0, class_1])\n",
    "    \n",
    "    return sampled_data\n",
    "\n",
    "\n",
    "# Уменьшение числа наблюдений с частым ответом\n",
    "data_downsampled = downsampling(data, 'target_column', 0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Применение линейной регрессии (10 баллов)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это задача классификации, но её можно решить с помощью линейной регрессии, если округлять предсказанный ответ до целого и выбирать ближайший по значению ответ из множества {0, 1}.\n",
    "\n",
    "Вынесите признак 'Claim' в вектор ответов и разделите датасет на обучающую и тестовую выборку в соотношении 80 к 20. Зафиксируйте random_state.\n",
    "\n",
    "**Подсказка:** быстро перевести Yes/No в 1/0 можно так - np.where(df['Claim'] == 'Yes', 1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Вынесение признака 'Claim' в вектор ответов\n",
    "y = np.where(data['Claim'] == 'Yes', 1, 0)\n",
    "\n",
    "# Удаление признака 'Claim' из датасета\n",
    "X = data.drop('Claim', axis=1)\n",
    "\n",
    "# Разделение датасета на обучающую и тестовую выборку\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Найдите аналитическое решение для обучающей выборки: обычное и регуляризацией l2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# посчитайте аналитическое решение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# посчитать аналитическое решение с регуляризацией"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Постройте модель LinearRegression, примените к тестовой выборке и посчитайте MSE (можно использовать библиотеку sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# обучите модель линейной регрессии LinearRegression на обучающей выборке, примените к тестовой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# посчитайте MSE, предварительно округлив предсказанные ответы до целого"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод (1 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишите краткий вывод по заданию (достаточно пары предложений). Расскажите, какие способы предобработки данных вы выбрали и почему. Насколько хороша ваша модель?"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Untitled9.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
